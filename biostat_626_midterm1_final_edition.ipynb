{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f62e105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from itertools import product\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492ba681",
   "metadata": {},
   "source": [
    "# Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "927dc3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load processed data, no transformation included\n",
    "data = pd.read_csv(\"binary_data_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12bb1ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>activity</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>...</th>\n",
       "      <th>F552</th>\n",
       "      <th>F553</th>\n",
       "      <th>F554</th>\n",
       "      <th>F555</th>\n",
       "      <th>F556</th>\n",
       "      <th>F557</th>\n",
       "      <th>F558</th>\n",
       "      <th>F559</th>\n",
       "      <th>F560</th>\n",
       "      <th>F561</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043580</td>\n",
       "      <td>-0.005970</td>\n",
       "      <td>-0.035054</td>\n",
       "      <td>-0.995381</td>\n",
       "      <td>-0.988366</td>\n",
       "      <td>-0.937382</td>\n",
       "      <td>-0.995007</td>\n",
       "      <td>-0.988816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012236</td>\n",
       "      <td>-0.314848</td>\n",
       "      <td>-0.713308</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841559</td>\n",
       "      <td>0.179913</td>\n",
       "      <td>-0.051718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039480</td>\n",
       "      <td>-0.002131</td>\n",
       "      <td>-0.029067</td>\n",
       "      <td>-0.998348</td>\n",
       "      <td>-0.982945</td>\n",
       "      <td>-0.971273</td>\n",
       "      <td>-0.998702</td>\n",
       "      <td>-0.983315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202804</td>\n",
       "      <td>-0.603199</td>\n",
       "      <td>-0.860677</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.845092</td>\n",
       "      <td>0.180261</td>\n",
       "      <td>-0.047436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039978</td>\n",
       "      <td>-0.005153</td>\n",
       "      <td>-0.022651</td>\n",
       "      <td>-0.995482</td>\n",
       "      <td>-0.977314</td>\n",
       "      <td>-0.984760</td>\n",
       "      <td>-0.996415</td>\n",
       "      <td>-0.975835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440079</td>\n",
       "      <td>-0.404427</td>\n",
       "      <td>-0.761847</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.849230</td>\n",
       "      <td>0.180610</td>\n",
       "      <td>-0.042271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039785</td>\n",
       "      <td>-0.011809</td>\n",
       "      <td>-0.028916</td>\n",
       "      <td>-0.996194</td>\n",
       "      <td>-0.988569</td>\n",
       "      <td>-0.993256</td>\n",
       "      <td>-0.996994</td>\n",
       "      <td>-0.988526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430891</td>\n",
       "      <td>-0.138373</td>\n",
       "      <td>-0.491604</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848947</td>\n",
       "      <td>0.181907</td>\n",
       "      <td>-0.040826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038758</td>\n",
       "      <td>-0.002289</td>\n",
       "      <td>-0.023863</td>\n",
       "      <td>-0.998241</td>\n",
       "      <td>-0.986774</td>\n",
       "      <td>-0.993115</td>\n",
       "      <td>-0.998216</td>\n",
       "      <td>-0.986479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137735</td>\n",
       "      <td>-0.366214</td>\n",
       "      <td>-0.702490</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.848164</td>\n",
       "      <td>0.185124</td>\n",
       "      <td>-0.037080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7762</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048048</td>\n",
       "      <td>-0.042445</td>\n",
       "      <td>-0.065884</td>\n",
       "      <td>-0.195448</td>\n",
       "      <td>-0.278326</td>\n",
       "      <td>-0.219954</td>\n",
       "      <td>-0.282233</td>\n",
       "      <td>-0.305861</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008381</td>\n",
       "      <td>-0.596760</td>\n",
       "      <td>-0.879026</td>\n",
       "      <td>-0.190437</td>\n",
       "      <td>0.829718</td>\n",
       "      <td>0.206972</td>\n",
       "      <td>-0.425619</td>\n",
       "      <td>-0.792292</td>\n",
       "      <td>0.238580</td>\n",
       "      <td>0.056020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7763</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037639</td>\n",
       "      <td>0.006430</td>\n",
       "      <td>-0.044345</td>\n",
       "      <td>-0.235372</td>\n",
       "      <td>-0.302680</td>\n",
       "      <td>-0.232843</td>\n",
       "      <td>-0.322483</td>\n",
       "      <td>-0.354464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209452</td>\n",
       "      <td>-0.404418</td>\n",
       "      <td>-0.684496</td>\n",
       "      <td>0.064907</td>\n",
       "      <td>0.875679</td>\n",
       "      <td>-0.879033</td>\n",
       "      <td>0.400219</td>\n",
       "      <td>-0.772288</td>\n",
       "      <td>0.252653</td>\n",
       "      <td>0.056252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7764</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037451</td>\n",
       "      <td>-0.002724</td>\n",
       "      <td>0.021009</td>\n",
       "      <td>-0.218281</td>\n",
       "      <td>-0.378082</td>\n",
       "      <td>-0.076950</td>\n",
       "      <td>-0.304446</td>\n",
       "      <td>-0.400661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237003</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>-0.317314</td>\n",
       "      <td>0.052806</td>\n",
       "      <td>-0.266724</td>\n",
       "      <td>0.864404</td>\n",
       "      <td>0.701169</td>\n",
       "      <td>-0.779566</td>\n",
       "      <td>0.249121</td>\n",
       "      <td>0.047071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7765</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044011</td>\n",
       "      <td>-0.004536</td>\n",
       "      <td>-0.051242</td>\n",
       "      <td>-0.219202</td>\n",
       "      <td>-0.383350</td>\n",
       "      <td>-0.081035</td>\n",
       "      <td>-0.310419</td>\n",
       "      <td>-0.380233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069366</td>\n",
       "      <td>0.037919</td>\n",
       "      <td>-0.356579</td>\n",
       "      <td>-0.101360</td>\n",
       "      <td>0.700740</td>\n",
       "      <td>0.936674</td>\n",
       "      <td>-0.589479</td>\n",
       "      <td>-0.785603</td>\n",
       "      <td>0.246409</td>\n",
       "      <td>0.031700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7766</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.068954</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>-0.080323</td>\n",
       "      <td>-0.269336</td>\n",
       "      <td>-0.366553</td>\n",
       "      <td>-0.147294</td>\n",
       "      <td>-0.377332</td>\n",
       "      <td>-0.360597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>-0.400831</td>\n",
       "      <td>-0.742972</td>\n",
       "      <td>-0.280088</td>\n",
       "      <td>-0.007739</td>\n",
       "      <td>-0.056088</td>\n",
       "      <td>-0.616956</td>\n",
       "      <td>-0.783693</td>\n",
       "      <td>0.246785</td>\n",
       "      <td>0.042981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7767 rows Ã— 563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject  activity        F1        F2        F3        F4        F5  \\\n",
       "0           1         0  0.043580 -0.005970 -0.035054 -0.995381 -0.988366   \n",
       "1           1         0  0.039480 -0.002131 -0.029067 -0.998348 -0.982945   \n",
       "2           1         0  0.039978 -0.005153 -0.022651 -0.995482 -0.977314   \n",
       "3           1         0  0.039785 -0.011809 -0.028916 -0.996194 -0.988569   \n",
       "4           1         0  0.038758 -0.002289 -0.023863 -0.998241 -0.986774   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "7762       30         1  0.048048 -0.042445 -0.065884 -0.195448 -0.278326   \n",
       "7763       30         1  0.037639  0.006430 -0.044345 -0.235372 -0.302680   \n",
       "7764       30         1  0.037451 -0.002724  0.021009 -0.218281 -0.378082   \n",
       "7765       30         1  0.044011 -0.004536 -0.051242 -0.219202 -0.383350   \n",
       "7766       30         1  0.068954  0.001810 -0.080323 -0.269336 -0.366553   \n",
       "\n",
       "            F6        F7        F8  ...      F552      F553      F554  \\\n",
       "0    -0.937382 -0.995007 -0.988816  ... -0.012236 -0.314848 -0.713308   \n",
       "1    -0.971273 -0.998702 -0.983315  ...  0.202804 -0.603199 -0.860677   \n",
       "2    -0.984760 -0.996415 -0.975835  ...  0.440079 -0.404427 -0.761847   \n",
       "3    -0.993256 -0.996994 -0.988526  ...  0.430891 -0.138373 -0.491604   \n",
       "4    -0.993115 -0.998216 -0.986479  ...  0.137735 -0.366214 -0.702490   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7762 -0.219954 -0.282233 -0.305861  ... -0.008381 -0.596760 -0.879026   \n",
       "7763 -0.232843 -0.322483 -0.354464  ...  0.209452 -0.404418 -0.684496   \n",
       "7764 -0.076950 -0.304446 -0.400661  ...  0.237003  0.000207 -0.317314   \n",
       "7765 -0.081035 -0.310419 -0.380233  ...  0.069366  0.037919 -0.356579   \n",
       "7766 -0.147294 -0.377332 -0.360597  ...  0.002496 -0.400831 -0.742972   \n",
       "\n",
       "          F555      F556      F557      F558      F559      F560      F561  \n",
       "0    -0.112754  0.030400 -0.464761 -0.018446 -0.841559  0.179913 -0.051718  \n",
       "1     0.053477 -0.007435 -0.732626  0.703511 -0.845092  0.180261 -0.047436  \n",
       "2    -0.118559  0.177899  0.100699  0.808529 -0.849230  0.180610 -0.042271  \n",
       "3    -0.036788 -0.012892  0.640011 -0.485366 -0.848947  0.181907 -0.040826  \n",
       "4     0.123320  0.122542  0.693578 -0.615971 -0.848164  0.185124 -0.037080  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "7762 -0.190437  0.829718  0.206972 -0.425619 -0.792292  0.238580  0.056020  \n",
       "7763  0.064907  0.875679 -0.879033  0.400219 -0.772288  0.252653  0.056252  \n",
       "7764  0.052806 -0.266724  0.864404  0.701169 -0.779566  0.249121  0.047071  \n",
       "7765 -0.101360  0.700740  0.936674 -0.589479 -0.785603  0.246409  0.031700  \n",
       "7766 -0.280088 -0.007739 -0.056088 -0.616956 -0.783693  0.246785  0.042981  \n",
       "\n",
       "[7767 rows x 563 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cf687ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop(columns=['subject', 'activity'])\n",
    "Y_train = data['activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b827ab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_np = X_train.to_numpy()\n",
    "Y_train_np = Y_train.to_numpy()\n",
    "n_obs = X_train_np.shape[0]\n",
    "total_idx = np.array(list(range(n_obs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3df7bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_Selection(X_train, Y_train,X_valid,Y_valid,pca=False,n_comp_min=10,  n_comp_max=150, step = 10,verbose = True):\n",
    "    history = defaultdict(list)\n",
    "\n",
    "    #print(X_train.shape)\n",
    "    #print(Y_train[1:5])\n",
    "    #print(X_valid.shape)\n",
    "    #print(Y_valid[1:5])\n",
    "    if pca:\n",
    "        for i in range(n_comp_min,n_comp_max+1,step):\n",
    "            model_svm = svm.SVC()\n",
    "            model_log = LogisticRegression()\n",
    "            model_forest = RandomForestClassifier(n_estimators=700)\n",
    "            model_lda = LinearDiscriminantAnalysis()\n",
    "            model_nb = GaussianNB()\n",
    "            pca_model = PCA(n_components=i)\n",
    "            pca_model.fit(X_train)\n",
    "            X_train_pca = pca_model.transform(X_train)\n",
    "            pca_model_valid = PCA(n_components=i)\n",
    "            pca_model_valid.fit(X_valid)\n",
    "            X_valid_pca = pca_model_valid.transform(X_valid)\n",
    "            if verbose:\n",
    "                print(\"now the n_pc is:\" + str(i) )\n",
    "            model_svm.fit(X_train_pca, Y_train)\n",
    "            model_log.fit(X_train_pca, Y_train)\n",
    "            model_forest .fit(X_train_pca, Y_train)\n",
    "            model_lda.fit(X_train_pca, Y_train)\n",
    "            model_nb.fit(X_train_pca, Y_train)\n",
    "            pred_svm = np.mean(model_svm.predict(X_valid_pca)==Y_valid)\n",
    "            pred_log = np.mean(model_log.predict(X_valid_pca)==Y_valid)\n",
    "            pred_forest = np.mean(model_forest.predict(X_valid_pca)==Y_valid)\n",
    "            pred_lda =  np.mean(model_lda.predict(X_valid_pca)==Y_valid)\n",
    "            pred_nb = np.mean(model_nb.predict(X_valid_pca)==Y_valid)\n",
    "            history[\"svm\"].append(pred_svm)\n",
    "            history[\"log\"].append(pred_log)\n",
    "            history[\"forest\"].append(pred_forest)\n",
    "            history[\"lda\"].append(pred_lda)\n",
    "            history[\"nb\"].append(pred_nb)\n",
    "    else:\n",
    "            model_svm = svm.SVC()\n",
    "            model_log = LogisticRegression()\n",
    "            model_forest = RandomForestClassifier(n_estimators=700)\n",
    "            model_lda = LinearDiscriminantAnalysis()\n",
    "            model_nb = GaussianNB()\n",
    "\n",
    "            model_svm.fit(X_train, Y_train)\n",
    "            model_log.fit(X_train, Y_train)\n",
    "            model_forest .fit(X_train, Y_train)\n",
    "            model_lda.fit(X_train, Y_train)\n",
    "            model_nb.fit(X_train, Y_train)\n",
    "            #print(model_log)\n",
    "            pred_svm = np.mean(model_svm.predict(X_valid)==Y_valid)\n",
    "            pred_log = np.mean(model_log.predict(X_valid)==Y_valid)\n",
    "            pred_forest = np.mean(model_forest.predict(X_valid)==Y_valid)\n",
    "            pred_lda =  np.mean(model_lda.predict(X_valid)==Y_valid)\n",
    "            pred_nb = np.mean(model_nb.predict(X_valid)==Y_valid)\n",
    "            history[\"svm\"].append(pred_svm)\n",
    "            history[\"log\"].append(pred_log)\n",
    "            history[\"forest\"].append(pred_forest)\n",
    "            history[\"lda\"].append(pred_lda)\n",
    "            history[\"nb\"].append(pred_nb)\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02eac6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extarct_results(model,data):\n",
    "    data = data[model]\n",
    "    mean_list = []\n",
    "    std_list = []\n",
    "    for mean, std in data:\n",
    "        mean_list.append(mean)\n",
    "        std_list.append(std)\n",
    "    return mean_list, std_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31a23fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:10\n",
      "now the n_pc is:20\n",
      "now the n_pc is:30\n",
      "now the n_pc is:40\n",
      "now the n_pc is:50\n",
      "now the n_pc is:10\n",
      "now the n_pc is:20\n",
      "now the n_pc is:30\n",
      "now the n_pc is:40\n",
      "now the n_pc is:50\n",
      "now the n_pc is:10\n",
      "now the n_pc is:20\n",
      "now the n_pc is:30\n",
      "now the n_pc is:40\n",
      "now the n_pc is:50\n",
      "now the n_pc is:10\n",
      "now the n_pc is:20\n",
      "now the n_pc is:30\n",
      "now the n_pc is:40\n",
      "now the n_pc is:50\n",
      "now the n_pc is:10\n",
      "now the n_pc is:20\n",
      "now the n_pc is:30\n",
      "now the n_pc is:40\n",
      "now the n_pc is:50\n"
     ]
    }
   ],
   "source": [
    "# 5 holdouts test\n",
    "results = {}\n",
    "for i in range(5):\n",
    "    np.random.seed(123+i)\n",
    "    idx_train = np.random.choice(total_idx,int(n_obs*0.2),replace = False)\n",
    "    idx_valid = np.setdiff1d(total_idx,idx_train)\n",
    "    X_train_sub = X_train_np[idx_train]\n",
    "    X_valid_sub = X_train_np[idx_valid]\n",
    "    Y_train_sub = Y_train_np [idx_train]\n",
    "    Y_valid_sub = Y_train_np [idx_valid]\n",
    "    results[i] = Model_Selection(X_train_sub ,Y_train_sub,X_valid_sub,Y_valid_sub ,n_comp_min=10,\n",
    "                            n_comp_max = 50, step = 10,pca = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f7b1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pca = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2612fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 holdouts test, no PCA\n",
    "results = {}\n",
    "for i in range(5):\n",
    "    np.random.seed(123+i)\n",
    "    idx_train = np.random.choice(total_idx,int(n_obs*0.2),replace = False)\n",
    "    idx_valid = np.setdiff1d(total_idx,idx_train)\n",
    "    X_train_sub = X_train_np[idx_train]\n",
    "    X_valid_sub = X_train_np[idx_valid]\n",
    "    Y_train_sub = Y_train_np [idx_train]\n",
    "    Y_valid_sub = Y_train_np [idx_valid]\n",
    "    results[i] = Model_Selection(X_train_sub ,Y_train_sub,X_valid_sub,Y_valid_sub ,n_comp_min=10,\n",
    "                            n_comp_max = 50, step = 10,pca = False )\n",
    "results_raw = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c29634f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pc_list = [10,20,30,40,50]\n",
    "model_list = [\"svm\",\"log\",\"forest\",\"lda\",\"nb\"]\n",
    "summary_dict = defaultdict(list)\n",
    "for model in model_list:\n",
    "    for i in range(5):\n",
    "        #current_pc = pc_list[i]\n",
    "        tmp = [results_pca[0][model][i],results_pca[1][model][i],results_pca[2][model][i],results_pca[3][model][i], \n",
    "                         results_pca[4][model][i]]\n",
    "        mean_acc = np.mean(tmp)\n",
    "        sd_acc = np.std(tmp)\n",
    "        summary_dict[model].append((mean_acc,sd_acc))\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a191545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_list:\n",
    "    tmp = [results_raw[0][model][0],results_raw[1][model][0],results_raw[2][model][0],results_raw[3][model][0], \n",
    "                         results_raw[4][model][0]]\n",
    "    mean_acc = np.mean(tmp)\n",
    "    sd_acc = np.std(tmp)\n",
    "    summary_dict[model].append((mean_acc,sd_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1cecdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_mean,svm_std = extarct_results(\"svm\",summary_dict)\n",
    "log_mean,log_std = extarct_results(\"log\",summary_dict)\n",
    "forest_mean,forest_std = extarct_results(\"forest\",summary_dict)\n",
    "lda_mean,lda_std = extarct_results(\"lda\",summary_dict)\n",
    "nb_mean,nb_std = extarct_results(\"nb\",summary_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd2d2e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_binary = pd.DataFrame({\"PCs\":[10,20,30,40,50,\"no_pc\"],\"svm_mean\":svm_mean, \"svm_std\":svm_std,\n",
    "                                \"log_mean\":log_mean,\"log_std\":log_std,\"forest_mean\":forest_mean,\"forest_std\":forest_std,\n",
    "                                \"lda_mean\":lda_mean, \"lda_std\":lda_std,\"nb_mean\":nb_mean, \"nb_std\":nb_std})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa18a504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "svm_mean       0.998487\n",
       "svm_std        0.011832\n",
       "log_mean       0.999067\n",
       "log_std        0.006747\n",
       "forest_mean    0.996846\n",
       "forest_std     0.008726\n",
       "lda_mean       0.998648\n",
       "lda_std        0.010322\n",
       "nb_mean        0.986804\n",
       "nb_std         0.001926\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_binary.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da948544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCs</th>\n",
       "      <th>svm_mean</th>\n",
       "      <th>svm_std</th>\n",
       "      <th>log_mean</th>\n",
       "      <th>log_std</th>\n",
       "      <th>forest_mean</th>\n",
       "      <th>forest_std</th>\n",
       "      <th>lda_mean</th>\n",
       "      <th>lda_std</th>\n",
       "      <th>nb_mean</th>\n",
       "      <th>nb_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.983167</td>\n",
       "      <td>0.010856</td>\n",
       "      <td>0.980850</td>\n",
       "      <td>0.006747</td>\n",
       "      <td>0.986707</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>0.977213</td>\n",
       "      <td>0.009335</td>\n",
       "      <td>0.974348</td>\n",
       "      <td>0.001070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.987126</td>\n",
       "      <td>0.010855</td>\n",
       "      <td>0.987930</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>0.987351</td>\n",
       "      <td>0.007893</td>\n",
       "      <td>0.986064</td>\n",
       "      <td>0.010322</td>\n",
       "      <td>0.975861</td>\n",
       "      <td>0.001926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0.986386</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.986772</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.987255</td>\n",
       "      <td>0.007802</td>\n",
       "      <td>0.985581</td>\n",
       "      <td>0.010039</td>\n",
       "      <td>0.971999</td>\n",
       "      <td>0.000755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.986386</td>\n",
       "      <td>0.011832</td>\n",
       "      <td>0.986643</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>0.987287</td>\n",
       "      <td>0.006910</td>\n",
       "      <td>0.985066</td>\n",
       "      <td>0.009692</td>\n",
       "      <td>0.972288</td>\n",
       "      <td>0.001770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.986482</td>\n",
       "      <td>0.011549</td>\n",
       "      <td>0.987029</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>0.985710</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>0.985163</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>0.971194</td>\n",
       "      <td>0.001478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no_pc</td>\n",
       "      <td>0.998487</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.999067</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.996846</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.998648</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.986804</td>\n",
       "      <td>0.000455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PCs  svm_mean   svm_std  log_mean   log_std  forest_mean  forest_std  \\\n",
       "0     10  0.983167  0.010856  0.980850  0.006747     0.986707    0.008726   \n",
       "1     20  0.987126  0.010855  0.987930  0.004750     0.987351    0.007893   \n",
       "2     30  0.986386  0.011593  0.986772  0.005373     0.987255    0.007802   \n",
       "3     40  0.986386  0.011832  0.986643  0.005633     0.987287    0.006910   \n",
       "4     50  0.986482  0.011549  0.987029  0.005713     0.985710    0.008513   \n",
       "5  no_pc  0.998487  0.000415  0.999067  0.000503     0.996846    0.001398   \n",
       "\n",
       "   lda_mean   lda_std   nb_mean    nb_std  \n",
       "0  0.977213  0.009335  0.974348  0.001070  \n",
       "1  0.986064  0.010322  0.975861  0.001926  \n",
       "2  0.985581  0.010039  0.971999  0.000755  \n",
       "3  0.985066  0.009692  0.972288  0.001770  \n",
       "4  0.985163  0.010079  0.971194  0.001478  \n",
       "5  0.998648  0.000745  0.986804  0.000455  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb3b306",
   "metadata": {},
   "source": [
    "logestic regression without pca seems to have the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28fec39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_binary.to_csv(\"summary_binary.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4b2e7c",
   "metadata": {},
   "source": [
    "**we choose logestic regression without pca as our final model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74bebceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test_data.csv\")\n",
    "X_test = test_data.drop(columns=['subject']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94138dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_log = LogisticRegression()\n",
    "model_log.fit(X_train_np, Y_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba670084",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_bin = pd.DataFrame(model_log.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "486be704",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_bin.to_csv(\"binary_fine.txt\",index=False,header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574d3363",
   "metadata": {},
   "source": [
    "# Multiclass Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc08590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mul_data = pd.read_csv(\"multi_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84acfd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_mul_data.drop(columns=['subject', 'activity'])\n",
    "Y_train = training_mul_data['activity']\n",
    "X_train_np = X_train.to_numpy()\n",
    "Y_train_np = Y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66c1ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test_data.csv\")\n",
    "X_test = test_data.drop(columns=['subject']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4186bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the n_pc is:50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "# 5 holdouts test\n",
    "results = {}\n",
    "for i in range(5):\n",
    "    np.random.seed(123+i)\n",
    "    idx_train = np.random.choice(total_idx,int(n_obs*0.2),replace = False)\n",
    "    idx_valid = np.setdiff1d(total_idx,idx_train)\n",
    "    X_train_sub = X_train_np[idx_train]\n",
    "    X_valid_sub = X_train_np[idx_valid]\n",
    "    Y_train_sub = Y_train_np [idx_train]\n",
    "    Y_valid_sub = Y_train_np [idx_valid]\n",
    "    results[i] = Model_Selection(X_train_sub ,Y_train_sub,X_valid_sub,Y_valid_sub ,n_comp_min=10,\n",
    "                            n_comp_max = 50, step = 10,pca = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f36d9211",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pca = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6548b3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/wzqian/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "# 5 holdouts test, no PCA\n",
    "results = {}\n",
    "for i in range(5):\n",
    "    np.random.seed(123+i)\n",
    "    idx_train = np.random.choice(total_idx,int(n_obs*0.2),replace = False)\n",
    "    idx_valid = np.setdiff1d(total_idx,idx_train)\n",
    "    X_train_sub = X_train_np[idx_train]\n",
    "    X_valid_sub = X_train_np[idx_valid]\n",
    "    Y_train_sub = Y_train_np [idx_train]\n",
    "    Y_valid_sub = Y_train_np [idx_valid]\n",
    "    results[i] = Model_Selection(X_train_sub ,Y_train_sub,X_valid_sub,Y_valid_sub ,n_comp_min=10,\n",
    "                            n_comp_max = 50, step = 10,pca = False )\n",
    "results_raw = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef089179",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\"svm\",\"log\",\"forest\",\"lda\",\"nb\"]\n",
    "summary_dict = defaultdict(list)\n",
    "for model in model_list:\n",
    "    for i in range(5):\n",
    "        #current_pc = pc_list[i]\n",
    "        tmp = [results_pca[0][model][i],results_pca[1][model][i],results_pca[2][model][i],results_pca[3][model][i], \n",
    "                         results_pca[4][model][i]]\n",
    "        mean_acc = np.mean(tmp)\n",
    "        sd_acc = np.std(tmp)\n",
    "        summary_dict[model].append((mean_acc,sd_acc))\n",
    "for model in model_list:\n",
    "    tmp = [results_raw[0][model][0],results_raw[1][model][0],results_raw[2][model][0],results_raw[3][model][0], \n",
    "                         results_raw[4][model][0]]\n",
    "    mean_acc = np.mean(tmp)\n",
    "    sd_acc = np.std(tmp)\n",
    "    summary_dict[model].append((mean_acc,sd_acc))\n",
    "svm_mean,svm_std = extarct_results(\"svm\",summary_dict)\n",
    "log_mean,log_std = extarct_results(\"log\",summary_dict)\n",
    "forest_mean,forest_std = extarct_results(\"forest\",summary_dict)\n",
    "lda_mean,lda_std = extarct_results(\"lda\",summary_dict)\n",
    "nb_mean,nb_std = extarct_results(\"nb\",summary_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "934eeccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_multi = pd.DataFrame({\"PCs\":[10,20,30,40,50,\"no_pc\"],\"svm_mean\":svm_mean, \"svm_std\":svm_std,\n",
    "                                \"log_mean\":log_mean,\"log_std\":log_std,\"forest_mean\":forest_mean,\"forest_std\":forest_std,\n",
    "                                \"lda_mean\":lda_mean, \"lda_std\":lda_std,\"nb_mean\":nb_mean, \"nb_std\":nb_std})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03ebc5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCs</th>\n",
       "      <th>svm_mean</th>\n",
       "      <th>svm_std</th>\n",
       "      <th>log_mean</th>\n",
       "      <th>log_std</th>\n",
       "      <th>forest_mean</th>\n",
       "      <th>forest_std</th>\n",
       "      <th>lda_mean</th>\n",
       "      <th>lda_std</th>\n",
       "      <th>nb_mean</th>\n",
       "      <th>nb_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.705439</td>\n",
       "      <td>0.048965</td>\n",
       "      <td>0.670518</td>\n",
       "      <td>0.064091</td>\n",
       "      <td>0.717509</td>\n",
       "      <td>0.033424</td>\n",
       "      <td>0.693981</td>\n",
       "      <td>0.024422</td>\n",
       "      <td>0.694689</td>\n",
       "      <td>0.027052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.713808</td>\n",
       "      <td>0.054227</td>\n",
       "      <td>0.656646</td>\n",
       "      <td>0.071138</td>\n",
       "      <td>0.731413</td>\n",
       "      <td>0.028689</td>\n",
       "      <td>0.689218</td>\n",
       "      <td>0.035064</td>\n",
       "      <td>0.715481</td>\n",
       "      <td>0.029434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0.710492</td>\n",
       "      <td>0.046422</td>\n",
       "      <td>0.650241</td>\n",
       "      <td>0.057469</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.027155</td>\n",
       "      <td>0.678436</td>\n",
       "      <td>0.049893</td>\n",
       "      <td>0.712037</td>\n",
       "      <td>0.033829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.714387</td>\n",
       "      <td>0.039527</td>\n",
       "      <td>0.660251</td>\n",
       "      <td>0.038832</td>\n",
       "      <td>0.730415</td>\n",
       "      <td>0.028429</td>\n",
       "      <td>0.678436</td>\n",
       "      <td>0.047094</td>\n",
       "      <td>0.709527</td>\n",
       "      <td>0.032805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.712810</td>\n",
       "      <td>0.043077</td>\n",
       "      <td>0.658159</td>\n",
       "      <td>0.038394</td>\n",
       "      <td>0.729063</td>\n",
       "      <td>0.029857</td>\n",
       "      <td>0.675443</td>\n",
       "      <td>0.050947</td>\n",
       "      <td>0.707757</td>\n",
       "      <td>0.032978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no_pc</td>\n",
       "      <td>0.935050</td>\n",
       "      <td>0.004313</td>\n",
       "      <td>0.969102</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>0.958964</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.972256</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.704892</td>\n",
       "      <td>0.084601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PCs  svm_mean   svm_std  log_mean   log_std  forest_mean  forest_std  \\\n",
       "0     10  0.705439  0.048965  0.670518  0.064091     0.717509    0.033424   \n",
       "1     20  0.713808  0.054227  0.656646  0.071138     0.731413    0.028689   \n",
       "2     30  0.710492  0.046422  0.650241  0.057469     0.730769    0.027155   \n",
       "3     40  0.714387  0.039527  0.660251  0.038832     0.730415    0.028429   \n",
       "4     50  0.712810  0.043077  0.658159  0.038394     0.729063    0.029857   \n",
       "5  no_pc  0.935050  0.004313  0.969102  0.002376     0.958964    0.003465   \n",
       "\n",
       "   lda_mean   lda_std   nb_mean    nb_std  \n",
       "0  0.693981  0.024422  0.694689  0.027052  \n",
       "1  0.689218  0.035064  0.715481  0.029434  \n",
       "2  0.678436  0.049893  0.712037  0.033829  \n",
       "3  0.678436  0.047094  0.709527  0.032805  \n",
       "4  0.675443  0.050947  0.707757  0.032978  \n",
       "5  0.972256  0.001286  0.704892  0.084601  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c514fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_multi.to_csv(\"summary_multi.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2e1a0c",
   "metadata": {},
   "source": [
    "**lda without pca has the best performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f7fbb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lda = LinearDiscriminantAnalysis()\n",
    "model_lda .fit(X_train_np, Y_train_np)\n",
    "multi_pred = model_lda.predict(X_test)\n",
    "prediction_multi = pd.DataFrame(multi_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5263b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_multi.to_csv(\"multiclass_fine.txt\",index=False,header = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
